{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Pitch and Plan for Solving a Domain Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to this notebook on github:\n",
    "\n",
    "[https://github.com/pitwegner/UTS_ML2019_ID13691340/blob/master/A3_Report.ipynb](https://github.com/pitwegner/UTS_ML2019_ID13691340/blob/master/A3_Report.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nursing Activity Recognition for Documentation and Clinical Guideline Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of the project is the development of a software system for the recognition of nursing activities based on worn acceleration sensors, in order to ease medical documentation and support clinical guideline compliance. The main goal can be divided into smaller objectives as follows:\n",
    "1. Initial Data Source Discovery\n",
    "2. Development and Evaluation of Existing and New Classifiers\n",
    "3. Ethical and Legal Approval\n",
    "4. Model Applicability in Real World Setting\n",
    "5. Efficient an Empathetic User Interface\n",
    "6. Deployment & Market Entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although activity recognition has been studied for a long time now, research and applications have been mainly focused on physical activity recognition. Many commercial products can now recognize when we walk, cycle or run, count steps and give a general overview of how active we have been on a day (Lester et al. 2006, Bao & Intille 2004, Tsinganos & Skodras 2017). However, research in applications to domains like healthcare, although advertised and highly regarded as important, is not very mature. One reason is that the activities are more complex and hard to analyze. Even if many application domains require the recognition of more complex activities, for example daily living activities or work-related activities, research on such activities has attracted less attention. Complex activity recognition in health care applications has been focusing on recognition of patient activities and overlooked nurses and caregivers (Chernbumroong et al. 2013).\n",
    "\n",
    "Nursing activity recognition is challenging because, unlike other activity settings in which the user is doing an activity, nurses usually perform some activity to a patient. For example, they give a drink to the patient instead of just drinking. This property introduces challenges that are not studied in other activity recognition applications. For example, the activities can be performed differently by the same nurse depending on the patient receiving the care. In this case, intra-class variability depends not only on the subject, as in other domains, but also on the receiving patient.\n",
    "\n",
    "Human Activity Recognition has been tackled using many different methods, including simple statistical analyses, various shallow methods, such as for example Hidden Markov Models, Support Vector Machines and Naïve Bayes, and deep learning techniques, such as CNN, RNN and temporal CNN (Reining et al. 2019). The data used is usually captured from acceleration sensors or Optical Motion Capture Cameras, while the X, Y and Z components are generally considered as multiple input channels. Data pre-processing often involves manual feature extraction relating to statistical time and frequency measures and application-based features. Techniques using CNN usually omit manual feature extraction and rely on the concolutional capabilities. All approaches have in common that they use a fixed window size for activity segmentation, although activity lengths differ wildly depending on type and subject (Lago et al. 2019). The proposed approach uses the complete inferred positional data of one activity (derived from numerical integration or a machine learning model), mapped in real space, as an input to a CNN. This way, the structural recognition capabilities of CNN can be applied to the entire activity. Different models could either work in 3D space directly or use 2D inputs after performing a Principal Component Analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nursing domain is one of the domains that can benefit enormously from activity recognition, but has not been researched due to lack of datasets and complexity. Recognition of nurse activities can have many applications like automatic record creation to reduce documentation time, checking compliance with care routines for a given patient and identification of risk activities that require special preparations and follow ups, for example hand washing after taking blood samples. All of these applications in the end increase patient safety in all nurse care domains. Commercial application of activity recognition in hospitals has the additional barrier of privacy concerns. The benefit of the approach to use acceleration data only, as opposed to motion capture or cameras, is the inherent data protection. Extracting personal information from such data is not trivially done, yet the motion patterns important for activity recognition are preserved. Using acceleration data for predicting human activities is also quite common, on the base of which the new approach can be built upon.\n",
    "\n",
    "The necessary tasks and their timeline to achieve a timely fulfillment iover the course of a year are outlined in the chart below. The critical milestones (prototype development and ethical approval) are set to be achieved within the first 3 months of the project, leaving the ability to \"fail early and often\". The second phase, which again covers about 3 months, involves the adjustment of the model based on real customer data and the development of a complete software prototype. The second half of the project is planned to include finishing the software by means of on-site testing, collecting further data, feedback for features and interfaces, as well as the full deployment to the customer's facilities and a final bug testing and maintenance phase.\n",
    "\n",
    "![Project Timeline](timeline.png \"Project Timeline\")\n",
    "\n",
    "The real world data collection for model testing needs to be minimally invasive for the daily work of the nurses. The positioning of acceleration sensors has to be confirmed with the nurses to not inhibit their work, yet still be in meaningful spots. Typical positions are joints and extremities, as well as the lower back and head. Furthermore, data labels have to be collected reliably, yet without much time overhead. Thus, a device similar to an n-sided die with an internal acceleration sensor could be designed that has the different activity labels as sides. The nurse would, each time a new activity is started, activate the die and set it with the corresponding side up on a flat surface. The data recording can be done by a crude smartphone app, connecting to the sensors via bluetooth.\n",
    "  \n",
    "The outcome of the project will be a cross-platform software that can be utilized to pre-fill nurse-specific activity reports based on analyzed data from body-worn IMU sensors, selected from pre-defined and pre-trained activities. This will majorly increase report completeness and quality, as well as reduce the amount of time required to create such a report. As these reports are used to check on clinical guideline compliance, the software also helps managers to detect areas of improvement. Due to the portability of the sensors, the software can be deployed in various environments, such as nursing homes, hospitals, and even home care. For special customers, new models could be trained on own data and activities additional to the common dataset, in order to include more activities and better prediction results. Besides the prediction model, the labelling die by itself could be sold as a secondary product for the software solution. It can be a useful tool in similar domains by semi-automating the documentation. The product would thus come in four different tiers: a completely manual documentation software, the semi-automated version with the labelling cube, a \"one size fits it all\" pre-trained model for activity prediction, and the highly customized, continuously learning model. Considering the market size and ever-growing trend, investing in the project in exchange for company shares poses a great return on investment. Average ages are rising and nursing care will undoubtedly be of major importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the project is estimated to cost about 500,000 AUD. This accounts majorly for wages and infrastructure (see table below). The prices are based on German estimates in € and then converted to AUD. The GPU infrastructure proposed includes either a rented cluster or a K20-machine on premise. The sensor hardware includes one full body set of Bonsai Systems IMU sensors (online store: https://store.bonsai-systems.com/motion-capturing/9-quantimotion-full-body-set.html), which incorporate a 3-axis gyroscope, a 3-axis accelerometer, and a 3-axis magnetometer. The devops position listed in the table refers to a website, code hosting, continuous integration and team collaboration. These services can either be rented or hosted on an own server.\n",
    "\n",
    "| Position           | # | Price  | Sum     |\n",
    "|--------------------|---|--------|---------|\n",
    "| Salary             | 5 | 88,000 | 440,000 |\n",
    "| Office Rental      | 1 | 20,000 |  20,000 |\n",
    "| PCs + Peripherals  | 5 |   2500 |  12,500 |\n",
    "| GPU Infrastructure | 1 |   2000 |    2000 |\n",
    "| Sensor Hardware    | 1 |   4000 |    4000 |\n",
    "| DevOps             | 1 |   1000 |    1000 |\n",
    "| Office Equipment   | 1 |   1000 |    1000 |\n",
    "| &#xfeff;  | &#xfeff; | &#xfeff; | 480,500 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum personnel required to successfully complete the project include a data scientist, a full stack developer and an advisor for ethical and legal requirements. In order to ensure timely delivery and a product of high quality, both the data scientist and the full stack developer should be supported by another one each, totalling 4 developers. The data scientists are responsible for analyzing the data, determining which machine learning approach to use and then model the algorithm, before prototyping it for testing. The two full stack developers will develop the software solution that integrates the machine learning model into a usable application, providing mobile and web interfaces, as well as device communication and data flow schemes. It helps, if any one of the four computer scientists has experience with machine learning engineering, supporting an efficient and scalable algorithm implementation. The ethical and legal position ensures that the application does not interfere with medical device regulations and act as a contact for data privacy related questions. If the goal of the project is to found a new company, one employee each for accounting, marketing and back office should be employed, in order to keep the founding and management duties from distracting the developer team. The salaries and fees involved with that are additional to the outline presented in the previous chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\setlength{\\parindent}{0pt}\n",
    "\n",
    "[LES06][0]: Lester, J., Choudhury T. & Borriello, G. 2006, 'A Practical Approach to Recognizing Physical Activities', *Pervasive Computing*, pp. 1-16.\n",
    "\\hfill\\break\n",
    "\n",
    "[BAO04][1]: Bao, L. & Intille, S. S. 2004, 'Activity Recognition from User-Annotated Acceleration Data', *Pervasive Computing*, pp. 1-17.\n",
    "\\hfill\\break\n",
    "\n",
    "[TSI17][2]: Tsinganos, P. & Skodras, A. 2017, 'A smartphone-based fall detection system for the elderly', in *Proceedings of the 10th International Symposium on Image and Signal Processing and Analysis*. \n",
    "\\hfill\\break\n",
    "\n",
    "[CHE13][3]: Chernbumroong, A., Cang, S., Atkins, A. & Yu H. 2013, 'Elderly activities recognition and classification for applications in assisted living', *Expert Systems with Applications*, vol. 50, no. 5, pp. 1662-1674.\n",
    "\\hfill\\break\n",
    "\n",
    "[REI19][4]: Reining, C., Rueda, F. M. & Hompel, M. T. 2019,'Human Activity Recognition for Production and Logistics—A Systematic Literature Review', *Information (Switzerland)*.\n",
    "\\hfill\\break\n",
    "\n",
    "[LAG19][5]: Lago, P., Takeda, S., Shamma, A. S., Mairittha, T., Mairittha, N. & Inoue S. 2019, 'Open Lab Nursing Activity Recognition Challenge', *IEEE Dataport*.\n",
    "\n",
    "[0]:https://link.springer.com/chapter/10.1007/11748625_1\n",
    "[1]:https://link.springer.com/chapter/10.1007/978-3-540-24646-6_1\n",
    "[2]:https://ieeexplore.ieee.org/document/8073568\n",
    "[3]:https://www.sciencedirect.com/science/article/pii/S0957417412010585\n",
    "[4]:https://www.researchgate.net/publication/334657266_Human_Activity_Recognition_for_Production_and_Logistics-A_Systematic_Literature_Review\n",
    "[5]:https://ieee-dataport.org/competitions/nurse-care-activity-recognition-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Pitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video and presentation losely follows a classic startup pitch deck for a seed investment to found a new company.\n",
    "\n",
    "Link: [https://www.youtube.com/watch?v=LTocRZ4dU3o](https://www.youtube.com/watch?v=LTocRZ4dU3o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
